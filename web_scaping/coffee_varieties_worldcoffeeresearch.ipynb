{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping in World Coffee Research\n",
    "---\n",
    "- Obtain the arabica coffee varieties to understand the optimal growth for each varieties\n",
    "- All data is from [World Coffee Research](https://varieties.worldcoffeeresearch.org/varieties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the species name for navigating between pages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting html from the page using requests, and then formatting using beautifulsoup\n",
    "catalog_url = \"https://varieties.worldcoffeeresearch.org/varieties\"\n",
    "catalog_page = requests.get(catalog_url).text\n",
    "catalog_soup = soup(catalog_page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the location of urls located\n",
    "catalog_body = catalog_soup.find_all(\"a\", class_=\"variety-tile variety-tile--grid-item\")\n",
    "\n",
    "# create a list to store all the url in the catalog\n",
    "species_url_list = []\n",
    "for item in range(len(catalog_body)):\n",
    "    url = catalog_body[item][\"href\"]\n",
    "    species_url_list.append(url)\n",
    "\n",
    "# identify how many coffee species were found\n",
    "len(species_url_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting required information from the coffee species page\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to hold all the data and a list of header\n",
    "data = []\n",
    "header = [\"species name\", \"brief intro\", \"plant stature\", \"leaf tip colour\", \"bean size\", \"optimal altitude low (5N_5S)\", \n",
    "          \"optimal altitude mid (5-15N_5-15S)\", \"optimal altitude high (15N_15S)\", \"quality potential at high altitude\",\n",
    "          \"yield potential\", \"disease: coffee leaf rust\", \"disease: coffee berry disease\", \"disease: nematodes\",\n",
    "          \"nutrition requirment\", \"planting density\"]\n",
    "\n",
    "for url in range(len(species_url_list)):\n",
    "    #\n",
    "    species_url = species_url_list[url]\n",
    "    species_page = requests.get(species_url).text\n",
    "    species_soup = soup(species_page, \"html.parser\")\n",
    "\n",
    "    # extract useful information \n",
    "    row = [] # create a list for each row of the data\n",
    "\n",
    "    # extract the coffee species name without the unwanted itmes\n",
    "    name = species_soup.find(\"h1\", class_= \"toolbar__page-title\").text.split()\n",
    "    # Can use this code but will delete modified the original file. (unwanted_name = name.small.extract())\n",
    "    try:\n",
    "        unwanted_name = species_soup.find(\"h1\", class_= \"toolbar__page-title\").small.text\n",
    "    except:\n",
    "        pass\n",
    "    for x in name:\n",
    "        if x == unwanted_name:\n",
    "            name.remove(x)\n",
    "    species_name = \" \".join(name)\n",
    "    row.append(species_name)\n",
    "    print(f\"Processing {species_name}...\")\n",
    "    # finding the brief intro for the species\n",
    "    brief_intro = species_soup.find(\"div\", class_= \"variety__intro-text\").text.strip()\n",
    "    row.append(brief_intro)\n",
    "    try:\n",
    "        # finding the stature of the coffee species\n",
    "        stature = species_soup.find(\"div\", class_= \"attribute-tile stature\").find(\"div\", class_= \"value\").text.strip()\n",
    "        row.append(stature)\n",
    "        # finding the leaf tip colour\n",
    "        leaf_tip_colour = species_soup.find(\"div\", class_= \"attribute-tile color\").find(\"div\", class_= \"value\").text.strip()\n",
    "        row.append(leaf_tip_colour)\n",
    "        # extract the bean size\n",
    "        bean_size = species_soup.find(\"div\", class_= \"attribute-tile bean-size\").find(\"div\", class_= \"value\").text.strip()\n",
    "        row.append(bean_size)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # extract optimal altitude\n",
    "        altitude = species_soup.find(\"div\", class_= \"altitude-groups\").text.strip().split(\"\\n\\n\")\n",
    "        low_lat_5N_5S = altitude[1]\n",
    "        row.append(low_lat_5N_5S)\n",
    "        mid_lat_5S_15N_5S_15S = altitude[4]\n",
    "        row.append(mid_lat_5S_15N_5S_15S)\n",
    "        high_lat_15N_15S = altitude[7]  \n",
    "        row.append(high_lat_15N_15S)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # quality potential at high altitude (will the coffee bean quality affected a lot of with the altitude)\n",
    "        quality = species_soup.find(\"div\", class_= \"attribute-tile high-altitude-quality\").find(\"div\", class_= \"value\").text.strip()\n",
    "        row.append(quality)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # yield potential\n",
    "        yield_potential = species_soup.find(\"div\", class_= \"attribute-tile yield-potential\").find(\"div\", class_= \"value\").text.strip()\n",
    "        row.append(yield_potential)\n",
    "    except:\n",
    "        pass\n",
    "    try: \n",
    "        # plant disease that will affect the coffee plant grow (coffee leaf rust, coffee berry disease, nematodes)\n",
    "        coffee_leaf_rust = species_soup.find(\"div\", class_= \"attribute-tile rust\").find(\"div\", class_= \"value\").text.strip()\n",
    "        row.append(coffee_leaf_rust)\n",
    "        coffee_berry_disease = species_soup.find(\"div\", class_= \"attribute-tile cbd\").find(\"div\", class_= \"value\").text.strip()\n",
    "        row.append(coffee_berry_disease)\n",
    "        nematodes = species_soup.find(\"div\", class_= \"attribute-tile nematodes\").find(\"div\", class_= \"value\").text.strip()\n",
    "        row.append(nematodes)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # nutrition requirement\n",
    "        nutrition_req = species_soup.find(\"tr\", class_= \"row nutrition\").find(\"td\", class_= \"cell value\").text.strip()\n",
    "        row.append(nutrition_req)\n",
    "        # planting density\n",
    "        density = species_soup.find(\"tr\", class_= \"row density\").find(\"td\", class_= \"cell value\").text.strip()\n",
    "        row.append(density)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # putting all the species data into the datalist\n",
    "    data.append(row)\n",
    "    print(f\"{species_name} Sucessful\")\n",
    "\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "print(\"Data Retrieval Complete\")\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store into dataframe and export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all the data into dataframe for export data\n",
    "df = pd.DataFrame.from_records(data, columns= header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "df.to_csv(\"output_data_csv/coffee_plant_species.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5387b9da968551e43e0ccab31c37bebadc093c630309dcd510e17231b5b064a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
